{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c49ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import statistics\n",
    "import scipy.stats.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a288d",
   "metadata": {},
   "source": [
    "## Confidence Interval\n",
    "\n",
    "**CONFIDENCE INTERVAL** = (**POINT ESTIMATE** - **RELIABILITY FACTOR** x **STANDARD ERROR**, **POINT ESTIMATE** + **RELIABILITY FACTOR** x **STANDARD ERROR**)\n",
    "\n",
    "**RELIABILITY FACTOR** = Z-static or t-static based on the distribution of the data and knowledge of the sample data and population mean.\n",
    "\n",
    "**STANDARD ERROR** = $\\frac{\\text{Standard Deviation}}{\\sqrt{\\text{Sample Size}}}$\n",
    "\n",
    "**Margin of error** = **RELIABILITY FACTOR**  X  **STANDARD ERROR**\n",
    "\n",
    "When to use:\n",
    "1. **Z-score**:\n",
    "    - Large sample size (n>30)\n",
    "    - Population variance is known\n",
    "\n",
    "2. **t-score**:\n",
    "    - Small sample size (n<30)\n",
    "    - Population variance is unknown\n",
    "\n",
    "When population size is large and we don't know the population variance, then we can use **Central Limit Theorem (CLT)** to get multiple sample means from the given data and then use the t-score.\n",
    "\n",
    "1. Confidence interval looking into **single population** with **known population variance**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{CI} = \\bar{x} \\pm Z_{\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\end{equation}\n",
    "\n",
    "2. Confidence interval looking into **single population** with **unknown population variance**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{CI} = \\bar{x} \\pm  t_{n-1, \\frac{\\alpha}{2}} \\frac{s}{\\sqrt{n}}\n",
    "\\end{equation}\n",
    "\n",
    "3. Confidence interval looking into **2 dependent populations** with **unknown population variance**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{CI} = \\bar{d} \\pm  t_{n-1, \\frac{\\alpha}{2}} \\frac{s_{d}}{\\sqrt{n}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "d = \\left(x_{1} - y_{1}, x_{2} - y_{2}, x_{3} - y_{3}, ...., x_{n} - y_{n}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "4. Confidence interval looking into **2 independent populations** with **known population variance**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{CI} = \\left(\\bar{x} - \\bar{y}\\right) \\pm Z_{\\frac{\\alpha}{2}} \\sqrt{\\frac{\\sigma_{x}^{2}}{n_{x}} + \\frac{\\sigma_{y}^{2}}{n_{y}}}\n",
    "\\end{equation}\n",
    "\n",
    "5. Confidence interval looking into **2 independent populations** with **unknown population variance but assumed to be equal**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{CI} = \\left(\\bar{x} - \\bar{y}\\right) \\pm t_{n_{x}+n_{y}-2, \\frac{\\alpha}{2}} \\sqrt{\\frac{s_{p}^{2}}{n_{x}} + \\frac{s_{p}^{2}}{n_{y}}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "s_{p}^{2} = \\frac{\\left(n_{x} - 1\\right)s_{x}^{2} + \\left(n_{y} - 1\\right)s_{y}^{2}}{n_{x} + n_{y} - 2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc685bb8",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Sample Sales Data available on Kaggle contains Order Info, Sales, Customer, Shipping, etc., Used for Segmentation, Customer Analytics, Clustering and More. Inspired for retail analytics. (https://www.kaggle.com/kyanyoga/sample-sales-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "206ccd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDERNUMBER</th>\n",
       "      <th>QUANTITYORDERED</th>\n",
       "      <th>PRICEEACH</th>\n",
       "      <th>ORDERLINENUMBER</th>\n",
       "      <th>SALES</th>\n",
       "      <th>ORDERDATE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>QTR_ID</th>\n",
       "      <th>MONTH_ID</th>\n",
       "      <th>YEAR_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ADDRESSLINE1</th>\n",
       "      <th>ADDRESSLINE2</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>POSTALCODE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>TERRITORY</th>\n",
       "      <th>CONTACTLASTNAME</th>\n",
       "      <th>CONTACTFIRSTNAME</th>\n",
       "      <th>DEALSIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10107</td>\n",
       "      <td>30</td>\n",
       "      <td>95.70</td>\n",
       "      <td>2</td>\n",
       "      <td>2871.00</td>\n",
       "      <td>2/24/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>897 Long Airport Avenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>10022</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yu</td>\n",
       "      <td>Kwai</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10121</td>\n",
       "      <td>34</td>\n",
       "      <td>81.35</td>\n",
       "      <td>5</td>\n",
       "      <td>2765.90</td>\n",
       "      <td>5/7/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>59 rue de l'Abbaye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reims</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51100</td>\n",
       "      <td>France</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Henriot</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10134</td>\n",
       "      <td>41</td>\n",
       "      <td>94.74</td>\n",
       "      <td>2</td>\n",
       "      <td>3884.34</td>\n",
       "      <td>7/1/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>27 rue du Colonel Pierre Avia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75508</td>\n",
       "      <td>France</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Da Cunha</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10145</td>\n",
       "      <td>45</td>\n",
       "      <td>83.26</td>\n",
       "      <td>6</td>\n",
       "      <td>3746.70</td>\n",
       "      <td>8/25/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>78934 Hillside Dr.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>90003</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10159</td>\n",
       "      <td>49</td>\n",
       "      <td>100.00</td>\n",
       "      <td>14</td>\n",
       "      <td>5205.27</td>\n",
       "      <td>10/10/2003 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>7734 Strong St.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Julie</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>10350</td>\n",
       "      <td>20</td>\n",
       "      <td>100.00</td>\n",
       "      <td>15</td>\n",
       "      <td>2244.40</td>\n",
       "      <td>12/2/2004 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2004</td>\n",
       "      <td>...</td>\n",
       "      <td>C/ Moralzarzal, 86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28034</td>\n",
       "      <td>Spain</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Freyre</td>\n",
       "      <td>Diego</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>10373</td>\n",
       "      <td>29</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3978.51</td>\n",
       "      <td>1/31/2005 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>Torikatu 38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oulu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90110</td>\n",
       "      <td>Finland</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Koskitalo</td>\n",
       "      <td>Pirkko</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>10386</td>\n",
       "      <td>43</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4</td>\n",
       "      <td>5417.57</td>\n",
       "      <td>3/1/2005 0:00</td>\n",
       "      <td>Resolved</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>C/ Moralzarzal, 86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28034</td>\n",
       "      <td>Spain</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Freyre</td>\n",
       "      <td>Diego</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>10397</td>\n",
       "      <td>34</td>\n",
       "      <td>62.24</td>\n",
       "      <td>1</td>\n",
       "      <td>2116.16</td>\n",
       "      <td>3/28/2005 0:00</td>\n",
       "      <td>Shipped</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>1 rue Alsace-Lorraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toulouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31000</td>\n",
       "      <td>France</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Roulet</td>\n",
       "      <td>Annette</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>10414</td>\n",
       "      <td>47</td>\n",
       "      <td>65.52</td>\n",
       "      <td>9</td>\n",
       "      <td>3079.44</td>\n",
       "      <td>5/6/2005 0:00</td>\n",
       "      <td>On Hold</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>8616 Spinnaker Dr.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>51003</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yoshido</td>\n",
       "      <td>Juri</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2823 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
       "0           10107               30      95.70                2  2871.00   \n",
       "1           10121               34      81.35                5  2765.90   \n",
       "2           10134               41      94.74                2  3884.34   \n",
       "3           10145               45      83.26                6  3746.70   \n",
       "4           10159               49     100.00               14  5205.27   \n",
       "...           ...              ...        ...              ...      ...   \n",
       "2818        10350               20     100.00               15  2244.40   \n",
       "2819        10373               29     100.00                1  3978.51   \n",
       "2820        10386               43     100.00                4  5417.57   \n",
       "2821        10397               34      62.24                1  2116.16   \n",
       "2822        10414               47      65.52                9  3079.44   \n",
       "\n",
       "            ORDERDATE    STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
       "0      2/24/2003 0:00   Shipped       1         2     2003  ...   \n",
       "1       5/7/2003 0:00   Shipped       2         5     2003  ...   \n",
       "2       7/1/2003 0:00   Shipped       3         7     2003  ...   \n",
       "3      8/25/2003 0:00   Shipped       3         8     2003  ...   \n",
       "4     10/10/2003 0:00   Shipped       4        10     2003  ...   \n",
       "...               ...       ...     ...       ...      ...  ...   \n",
       "2818   12/2/2004 0:00   Shipped       4        12     2004  ...   \n",
       "2819   1/31/2005 0:00   Shipped       1         1     2005  ...   \n",
       "2820    3/1/2005 0:00  Resolved       1         3     2005  ...   \n",
       "2821   3/28/2005 0:00   Shipped       1         3     2005  ...   \n",
       "2822    5/6/2005 0:00   On Hold       2         5     2005  ...   \n",
       "\n",
       "                       ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
       "0           897 Long Airport Avenue           NaN            NYC    NY   \n",
       "1                59 rue de l'Abbaye           NaN          Reims   NaN   \n",
       "2     27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
       "3                78934 Hillside Dr.           NaN       Pasadena    CA   \n",
       "4                   7734 Strong St.           NaN  San Francisco    CA   \n",
       "...                             ...           ...            ...   ...   \n",
       "2818             C/ Moralzarzal, 86           NaN         Madrid   NaN   \n",
       "2819                    Torikatu 38           NaN           Oulu   NaN   \n",
       "2820             C/ Moralzarzal, 86           NaN         Madrid   NaN   \n",
       "2821          1 rue Alsace-Lorraine           NaN       Toulouse   NaN   \n",
       "2822             8616 Spinnaker Dr.           NaN         Boston    MA   \n",
       "\n",
       "     POSTALCODE  COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
       "0         10022      USA       NaN              Yu             Kwai    Small  \n",
       "1         51100   France      EMEA         Henriot             Paul    Small  \n",
       "2         75508   France      EMEA        Da Cunha           Daniel   Medium  \n",
       "3         90003      USA       NaN           Young            Julie   Medium  \n",
       "4           NaN      USA       NaN           Brown            Julie   Medium  \n",
       "...         ...      ...       ...             ...              ...      ...  \n",
       "2818      28034    Spain      EMEA          Freyre            Diego    Small  \n",
       "2819      90110  Finland      EMEA       Koskitalo           Pirkko   Medium  \n",
       "2820      28034    Spain      EMEA          Freyre            Diego   Medium  \n",
       "2821      31000   France      EMEA          Roulet          Annette    Small  \n",
       "2822      51003      USA       NaN         Yoshido             Juri   Medium  \n",
       "\n",
       "[2823 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sales_data_sample.csv', sep=\",\", encoding='Latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b635c8",
   "metadata": {},
   "source": [
    "###  Lets estimate the 95% confidence interval for sales for each country from 2003 to 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1e8ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        COUNTRY                                     CI_95\n",
      "0     Australia   (3131.8935623683346, 3706.573057349975)\n",
      "1       Austria    (2948.921260784013, 4093.829791847565)\n",
      "2       Belgium    (2726.481122465292, 3943.319677534708)\n",
      "3        Canada   (2752.527528867365, 3489.6229629359136)\n",
      "4       Denmark   (3182.4002800297058, 4138.409053303628)\n",
      "5       Finland   (3199.6979794785548, 4308.827946447372)\n",
      "6        France   (3241.1779414632206, 3702.503018536779)\n",
      "7       Germany   (3096.4756649974884, 4015.527238228318)\n",
      "8       Ireland    (2503.834247856112, 4715.719502143887)\n",
      "9         Italy  (3007.8059631171686, 3722.7873702161646)\n",
      "10        Japan     (2935.48255414086, 4179.873160144854)\n",
      "11       Norway   (3217.450179301049, 4016.9898206989515)\n",
      "12  Philippines    (2964.122816013692, 4267.856414755539)\n",
      "13    Singapore    (3245.414641142219, 4168.407200963044)\n",
      "14        Spain    (3307.378976668714, 3719.409560880693)\n",
      "15       Sweden     (3154.340556270969, 4127.59781107597)\n",
      "16  Switzerland   (3253.4455492734996, 4340.977676532952)\n",
      "17           UK    (3004.90609011936, 3485.1331691398996)\n",
      "18          USA   (3433.5764819308147, 3678.477192266569)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[df['YEAR_ID'].isin([2003,2004])]\n",
    "\n",
    "gpd_data = df1.groupby('COUNTRY')['SALES'].agg(['count','mean','std']).reset_index()\n",
    "gpd_data['std_error'] = gpd_data.apply(lambda row: row['std']/row['count']**0.5, axis = 1)\n",
    "gpd_data['CI_95'] = gpd_data.apply(lambda row: scipy.stats.t.interval(0.95, row['count']-1, row['mean'], row['std_error']), axis = 1)\n",
    "print(gpd_data[['COUNTRY','CI_95']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7704251",
   "metadata": {},
   "source": [
    "###  Lets estimate the 95% confidence interval for sales in cities Barcelona and Sevilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f0c5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI: [   0.         1336.91252641]\n"
     ]
    }
   ],
   "source": [
    "df1 = df1[df1['COUNTRY'] == 'Spain']\n",
    "df1 = df1[df1['CITY'].isin(['Barcelona','Sevilla'])]\n",
    "\n",
    "gpd_data = df1.groupby('CITY')['SALES'].agg(['count','mean','var']).to_dict()\n",
    "\n",
    "pooled_var = ( (gpd_data['count']['Barcelona']-1)*gpd_data['var']['Barcelona'] + \n",
    "              gpd_data['count']['Sevilla']*gpd_data['var']['Sevilla'] ) / (gpd_data['count']['Barcelona']+gpd_data['count']['Sevilla']-2)\n",
    "\n",
    "CI_95 = np.array(scipy.stats.t.interval(0.95, gpd_data['count']['Barcelona']+gpd_data['count']['Sevilla']-2, \n",
    "                      abs(gpd_data['mean']['Barcelona']-gpd_data['mean']['Sevilla']),\n",
    "                      (pooler_var/gpd_data['count']['Barcelona'] + pooler_var/gpd_data['count']['Sevilla'])**0.5))\n",
    "\n",
    "CI_95[CI_95<0] = 0\n",
    "\n",
    "print('CI:', CI_95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1fe3a",
   "metadata": {},
   "source": [
    "## **ANOVA Formulation:**\n",
    "\n",
    "Using ANOVA, identify if there is any significant difference between the mean of the three groups.\n",
    "\n",
    "$H_{0}:$ mean of all groups is equal\n",
    "\n",
    "$H_{A}:$ at least one of the means is different\n",
    "\n",
    "$SS_{total} = \\sum_{i=1}^{n} \\left(y_{i} - \\bar{y}\\right)^2 \\tag{0}$\n",
    "\n",
    "$SS_{residual} = \\sum_{j \\in G} \\left( \\sum_{i=1}^{n_{j}} \\left( y_{i,j} - \\bar{y_{j}} \\right)^2 \\right) \\forall G \\in \\{Group1, Group2, ..\\} \\tag{1}$\n",
    "\n",
    "$SS_{total} = SS_{explained} + SS_{residual} \\tag{2}$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$SS_{explained} = SS_{total} - SS_{residual} \\tag{3}$\n",
    "\n",
    "$df_{explained} = $ number of groups $- 1$\n",
    "\n",
    "$df_{residual} = $ number of observations - number of groups\n",
    "\n",
    "$MS_{explained} = \\frac{SS_{explained}}{df_{explained}} \\tag{4}$\n",
    "\n",
    "$MS_{residual} = \\frac{SS_{residual}}{df_{residual}} \\tag{5}$\n",
    "\n",
    "$F_{static} = \\frac{MS_{explained}}{MS_{residual}} \\tag{6}$\n",
    "\n",
    "**P-value** = $F\\left(df_{explained}, df_{residual}\\right)$\n",
    "\n",
    "$\\alpha$ = level of significance\n",
    "\n",
    "If **P-value** $\\lt \\alpha$ : We reject the $H_{0}$\n",
    "\n",
    "If **P-value** $\\gt \\alpha$ : We don't have enough evidence to reject the $H_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc953a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.7</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>28.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.2</td>\n",
       "      <td>23.6</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.4</td>\n",
       "      <td>25.3</td>\n",
       "      <td>30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.4</td>\n",
       "      <td>27.9</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B     C\n",
       "0   19.7  23.0  21.6\n",
       "1   20.1  24.5  25.5\n",
       "2   21.3  24.6  25.9\n",
       "3   23.5  27.1  30.7\n",
       "4    9.3  12.0   3.0\n",
       "5   27.1  27.8  16.5\n",
       "6   11.6  12.8  22.7\n",
       "7   12.2  16.2  24.2\n",
       "8   15.9  19.8  26.2\n",
       "9   17.0  22.4  28.4\n",
       "10  17.2  23.6  28.5\n",
       "11  18.4  25.3  30.7\n",
       "12  19.4  27.9  32.2\n",
       "13  23.4   4.6  33.8\n",
       "14   2.0  35.2  34.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['A'] = [19.7, 20.1, 21.3, 23.5,  9.3, 27.1, 11.6, 12.2, 15.9, 17. , 17.2, 18.4, 19.4, 23.4,  2. ]\n",
    "df['B'] = [23. , 24.5, 24.6, 27.1, 12. , 27.8, 12.8, 16.2, 19.8, 22.4, 23.6, 25.3, 27.9,  4.6, 35.2]\n",
    "df['C'] = [21.6, 25.5, 25.9, 30.7,  3. , 16.5, 22.7, 24.2, 26.2, 28.4, 28.5, 30.7, 32.2, 33.8, 34.5]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9b4c987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-stat: 4.9412309941313985\n",
      "P-value: 0.011825050132581727\n",
      "We can reject the Null Hypothesis at 0.05 significance level\n",
      "But we do have enough evidence to reject the Null Hypothesis at 0.01 significance level\n"
     ]
    }
   ],
   "source": [
    "total_mean = np.mean(df.iloc[:,:].values)\n",
    "A_mean = df['A'].mean()\n",
    "B_mean = df['B'].mean()\n",
    "C_mean = df['C'].mean()\n",
    "\n",
    "ss_total = np.sum((df.iloc[:,:].values - total_mean)**2)\n",
    "ss_residual = np.sum(np.sum((df['A'].values - A_mean)**2) + \n",
    "                     np.sum((df['B'].values - B_mean)**2) + \n",
    "                     np.sum((df['C'].values - C_mean)**2)\n",
    "                    )\n",
    "ss_explained = ss_total - ss_residual\n",
    "\n",
    "df1 = df.shape[1] - 1\n",
    "df2 = df.size - df.shape[1]\n",
    "\n",
    "ms_explained = ss_explained/df1\n",
    "ms_residual = ss_residual/df2\n",
    "\n",
    "f_static = ms_explained/ms_residual\n",
    "print('F-stat:', f_static)\n",
    "\n",
    "p_value = 1 - scipy.stats.f.cdf(f_static, df1, df2)\n",
    "print('P-value:', p_value)\n",
    "\n",
    "print('We can reject the Null Hypothesis at 0.05 significance level')\n",
    "print('But we do have enough evidence to reject the Null Hypothesis at 0.01 significance level')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4a34c",
   "metadata": {},
   "source": [
    "## Equality of Proportions\n",
    "\n",
    "To test if population proportions of two groups are significantly different using statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5363d2d",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We will be using popular Titanic data from Kaggle and see if the sex has any effect on the survival of an individual.\n",
    "(https://www.kaggle.com/c/titanic/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eff9b95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>81</td>\n",
       "      <td>233</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>468</td>\n",
       "      <td>109</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1  total\n",
       "Sex                      \n",
       "female     81  233    314\n",
       "male      468  109    577"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "pvt_data = data.pivot_table(index = 'Sex', columns = 'Survived', values = 'PassengerId', aggfunc = 'count')\n",
    "\n",
    "pvt_data['total'] = pvt_data.sum(axis = 1)\n",
    "\n",
    "pvt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce87dc0e",
   "metadata": {},
   "source": [
    "$p_{1}$ = proportion of females who survived\n",
    "\n",
    "$p_{2}$ = proportion of males who survived\n",
    "\n",
    "$p$ = proportion of survived from both sex combined\n",
    "\n",
    "$H_{0} : p_{1} - p_{2} = 0 \\tag{0}$\n",
    "\n",
    "$H_{A} : p_{1} - p_{2} \\ne 0 \\tag{1}$\n",
    "\n",
    "Test-statistic:\n",
    "\n",
    "\\begin{equation}\n",
    "Z = \\frac{\\left(p_{1} - p_{2}\\right) - 0}{\\sqrt{p(1-p)\\left(\\frac{1}{n_{1}}+\\frac{1}{n_{2}}\\right)}}\n",
    "\\tag{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "320089de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 3.7117477701134797e-59\n",
      "Since the P-value is very low, we can reject the null hypothesis and accept the alternate hypothesis.\n",
      "Hence the sex has a huge effect on the survival of an individual in the tragedy\n"
     ]
    }
   ],
   "source": [
    "p1 = 233/314\n",
    "p2 = 109/577\n",
    "p = (233+109)/(314+577)\n",
    "\n",
    "z_statistic = abs((p1-p2)/( p*(1-p) * (1/314 + 1/577) )**0.5)\n",
    "\n",
    "pvalue = 2*dist.norm.cdf(-np.abs(z_statistic)) # Multiplied by two indicates a two tailed testing.\n",
    "print('P-value:',pvalue)\n",
    "\n",
    "print('Since the P-value is very low, we can reject the null hypothesis and accept the alternate hypothesis.')\n",
    "print('Hence the sex has a huge effect on the survival of an individual in the tragedy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
